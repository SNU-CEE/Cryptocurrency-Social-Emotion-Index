{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0112_twitter.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Ma9DXoECZmWbf7QKwbWSObOijnwsXspd","authorship_tag":"ABX9TyPAbdbCmlT4JPZl0DVVXkNU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import re\n","import nltk\n","import tweepy\n","import numpy as np\n","import pandas as pd\n","from textblob import TextBlob\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","from collections import Counter\n"],"metadata":{"id":"F7sBPRC-CTp3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VFnz2a0twyiA"},"outputs":[],"source":["influencer = ['elonmusk', 'VitalikButerin', 'BillyM2k']\n","path = '/content/drive/MyDrive/2021-W_IAB/influencer/'\n","for account in influencer:\n","    globals()[account] = pd.read_csv(path+account+'.csv')\n","\n","news = ['BBCBreaking', 'TIME', 'cnnbrk', 'WSJ', 'washingtonpost', 'nytimes', 'BBCWorld', 'TheEconomist', 'Reuters']\n","path = '/content/drive/MyDrive/2021-W_IAB/news/'\n","for account in news:\n","    globals()[account] = pd.read_csv(path+account+'.csv')\n","\n","cryptocurrency = ['binance', 'CoinDesk', 'crypto', 'ForbesCrypto', 'dogecoin', 'dogecoin_devs', 'ethereum', 'Bitcoin', 'BTCTN']\n","path = '/content/drive/MyDrive/2021-W_IAB/cryptocurrency/'\n","for account in cryptocurrency:\n","    globals()[account] = pd.read_csv(path+account+'.csv')\n"]},{"cell_type":"code","source":["# Clean The Data\n","def cleantext(text):\n","    text = re.sub(r\"@[A-Za-z0-9]+\", \"\", text) # Remove Mentions\n","    text = re.sub(r\"#\", \"\", text) # Remove Hashtags Symbol\n","    text = re.sub(r\"RT[\\s]+\", \"\", text) # Remove Retweets\n","    text = re.sub(r\"https?:\\/\\/\\S+\", \"\", text) # Remove The Hyper Link\n","    return text\n","    \n","# Preprocessing Text Data\n","def preprocessing(text):\n","    sentences = []\n","    for sentence in text:\n","        x = sentence.split('\\n')\n","        if len(x) != 3:\n","            tweet = ''\n","            for word in x:\n","                if word == '':\n","                    continue\n","                elif word[0] == '이':\n","                    continue\n","                elif word[-1] not in '천만년월일수글기과다자표0123456789':\n","                    tweet = tweet + ' ' + word\n","                else:\n","                    continue\n","            sentences.append(tweet.strip())\n","    return sentences\n","\n","\n","for account in influencer:\n","    globals()[account]['Embedded_text'] = globals()[account]['Embedded_text'].apply(cleantext)\n","    globals()[f'{account}_text'] = preprocessing(globals()[account]['Embedded_text'])\n","    globals()[f'{account}_df'] = pd.DataFrame({'Tweets': globals()[f'{account}_text']})\n","    globals()[f'{account}_df'].name = account\n","\n","for account in news:\n","    globals()[account]['Embedded_text'] = globals()[account]['Embedded_text'].apply(cleantext)\n","    globals()[f'{account}_text'] = preprocessing(globals()[account]['Embedded_text'])\n","    globals()[f'{account}_df'] = pd.DataFrame({'Tweets': globals()[f'{account}_text']})\n","    globals()[f'{account}_df'].name = account\n","\n","for account in cryptocurrency:\n","    globals()[account]['Embedded_text'] = globals()[account]['Embedded_text'].apply(cleantext)\n","    globals()[f'{account}_text'] = preprocessing(globals()[account]['Embedded_text'])\n","    globals()[f'{account}_df'] = pd.DataFrame({'Tweets': globals()[f'{account}_text']})\n","    globals()[f'{account}_df'].name = account\n","\n","influencer_dfs = dict(zip(influencer, [globals()[f'{account}_df'] for account in influencer]))\n","news_dfs = dict(zip(news, [globals()[f'{account}_df'] for account in news]))\n","cryptocurrency_dfs = dict(zip(cryptocurrency, [globals()[f'{account}_df'] for account in cryptocurrency]))"],"metadata":{"id":"Cgz389UK7NXS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_subj(tweet):\n","    return TextBlob(tweet).sentiment.subjectivity\n"," \n","# function for Polarity\n","def calc_pola(tweet):\n","    return TextBlob(tweet).sentiment.polarity\n","\n","def sentiment(polarity):\n","    result = ''\n","    if polarity > 0:\n","        result = 'Positive'\n","    elif polarity == 0:\n","        result = 'Netural'\n","    else:\n","        result = 'Negative'\n","    return result\n","\n","\n","def add_sentiment(df):\n","    df['Subjectivity'] = df.Tweets.apply(calc_subj)\n","    df['Polarity'] = df.Tweets.apply(calc_pola)\n","    df['Sentiment'] = df.Polarity.apply(sentiment) \n","\n","\n","# elonmusk_df['Subjectivity'] = elonmusk_df.Tweets.apply(calc_subj)\n","# elonmusk_df['Polarity'] = elonmusk_df.Tweets.apply(calc_pola)\n","# # elonmusk_df['Sentiment'] = elonmusk_df.Polarity.apply(sentiment) \n","# add_sentiment(elonmusk_df)\n","# elonmusk_df"],"metadata":{"id":"3zoL5UYNnNsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's see how sentiment is distributed\n","\n","def plot_sentiment(df):\n","    plt.figure(figsize=(10,6))\n","\n","    plt.subplot(121)\n","    df.Sentiment.value_counts().plot(kind='bar', color='red')\n","    plt.title('Sentiment Classification')\n","    plt.ylabel('Count')\n","\n","    plt.subplot(122)\n","    plt.scatter(df.Polarity, df.Subjectivity, color='red')\n","    plt.title('Sentiment Analysis')\n","    plt.xlabel('Polarity')\n","    plt.ylabel('Subjectivity')\n","\n","    df_sentiment = pd.DataFrame({'Count': df.Sentiment.value_counts()})\n","    df_sentiment['Percentage'] = list(map(round, list(df.Sentiment.value_counts(normalize=True)*100)))\n","    return df_sentiment\n","\n","\n","# plot_sentiment(elonmusk_df)"],"metadata":{"id":"BZ15GWRR-4lM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Alright, let's see which word is used most by Elon\n","\n","# setting up stop words \n","nltk.download('stopwords')  # run this if you get any error\n","stpwrd = set(nltk.corpus.stopwords.words('english'))\n","\n","# word cloud\n","def Word_cloud(data, title, mask=None):\n","    Cloud = WordCloud(scale=3,\n","                      random_state=21,\n","                      colormap='autumn',\n","                      mask=mask,\n","                      stopwords=stpwrd,\n","                      collocations=True,).generate(data)\n","    plt.figure(figsize=(20,12))\n","    plt.imshow(Cloud)\n","    plt.axis('off')\n","    plt.title(title)\n","    plt.show()\n","\n","# plot it\n","def plot_wordcloud(df):\n","    # Combining all tweets text\n","    allWords = ' '.join([twts for twts in df['Tweets']])\n","    Word_cloud(allWords, df.name)\n","\n","# plot_wordcloud(elonmusk_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OepmbNV2E8cT","executionInfo":{"status":"ok","timestamp":1642748664661,"user_tz":-540,"elapsed":7,"user":{"displayName":"­김학순 / 학생 / 건설환경공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLQGJEsB4Jy-3ci7_I7hyLDRG_AwOZRR-xAVx5=s64","userId":"16966179105291263540"}},"outputId":"c7d6df50-0923-4825-a659-8e78bfd76c75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["# influencer_dfs = dict(zip(influencer, [globals()[f'{account}_df'] for account in influencer]))\n","# news_dfs = dict(zip(news, [globals()[f'{account}_df'] for account in news]))\n","# cryptocurrency_dfs = dict(zip(cryptocurrency, [globals()[f'{account}_df'] for account in cryptocurrency]))\n","\n","influencer_texts = dict(zip(influencer, [globals()[f'{account}_text'] for account in influencer]))\n","news_texts = dict(zip(news, [globals()[f'{account}_text'] for account in news]))\n","cryptocurrency_texts = dict(zip(cryptocurrency, [globals()[f'{account}_text'] for account in cryptocurrency]))\n","\n","all_texts = {**influencer_texts, **news_texts, **cryptocurrency_texts}\n","\n","all_texts_list = []\n","for text in all_texts.values():\n","    all_texts_list += text\n","all_texts_list_lower = list(map(lambda x: x.lower(), all_texts_list))\n"],"metadata":{"id":"4wbLwNFOS6ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 대소문자 상관없음\n","keywords_cryptocurrency = ['Cryptocurrency', 'Bitcoin', 'Ethereum', 'Coinbase', 'Doge', 'NFT', 'Binance']\n","keywords_news = ['Price', 'Market', 'Trading', 'Exchange', 'Invest', 'Wallet', 'Stock', 'Money', 'Digital', 'Liquidity', 'Crisis', 'Tapering', 'Regulation', 'crackdown', 'plunge']\n","keywords_influencer = ['Reddit', 'Meme', 'SpaceX']\n","keywords_insensitive = keywords_cryptocurrency + keywords_news + keywords_influencer\n","\n","# 대소문자 상관있음\n","keywords_sensitive = ['DeFi', 'Fed', 'AMC', 'GME']\n","\n","\n","# 단어 개수 카운트하는 함수 - input: 문장들을 포함한 리스트\n","def key_count(texts: list) -> dict:\n","    count_dict = dict(Counter(word for sentence in texts for word in sentence.split()))\n","    return count_dict\n","\n","\n","allwords_frequency_i = sorted(key_count(all_texts_list_lower).items(), key = lambda item: item[1], reverse = True)\n","allwords_frequency_s = sorted(key_count(all_texts_list).items(), key = lambda item: item[1], reverse = True)\n","\n","keywords_frequency_i = {}\n","keywords_frequency_s = {}\n","\n","for word in keywords_insensitive:\n","    n = 0\n","    for i in allwords_frequency_i:\n","        if word.lower() in i[0]:\n","            # print(i[0], i[1])\n","            n += i[1]\n","    # print(n)\n","    keywords_frequency_i[word] = n\n","\n","for word in keywords_sensitive:\n","    n = 0\n","    for i in allwords_frequency_s:\n","        if word in i[0]:\n","            # print(i[0], i[1])\n","            n += i[1]\n","    # print(n)\n","    keywords_frequency_s[word] = n\n","\n","# keywords_frequency_i\n","# keywords_frequency_s\n"],"metadata":{"id":"XYesv5mMtc3A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# results = []\n","# specific = [a for a in nytimes_text if 'crypto' in a]\n","# if len(specific) != 0:\n","#     for sentence in specific:\n","#         pol_score = SIA().polarity_scores(sentence) # run analysis\n","#         pol_score['sentence'] = sentence # add headlines for viewing\n","#         results.append(pol_score)\n","#     sentiment_df = pd.DataFrame(results)\n","#     mean_score = sentiment_df['compound'].mean()\n","# else:\n","#     mean_score = 0\n","\n","# sentiment_df\n"],"metadata":{"id":"AWd114nBTr1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('vader_lexicon')\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n","\n","# results = []\n","\n","def sentiment_score_s(keyword):\n","    results = []\n","    specific = [a for a in all_texts_list if keyword in a]\n","    if len(specific) != 0:\n","        for sentence in specific:\n","            pol_score = SIA().polarity_scores(sentence) # run analysis\n","            pol_score['sentence'] = sentence # add headlines for viewing\n","            results.append(pol_score)\n","        sentiment_df = pd.DataFrame(results)\n","        mean_score = sentiment_df['compound'].mean()\n","    else:\n","        mean_score = 0\n","    return mean_score\n","\n","def sentiment_score_i(keyword):\n","    results = []\n","    specific = [a for a in all_texts_list_lower if keyword.lower() in a]\n","    if len(specific) != 0:\n","        for sentence in specific:\n","            pol_score = SIA().polarity_scores(sentence) # run analysis\n","            pol_score['sentence'] = sentence # add headlines for viewing\n","            results.append(pol_score)\n","        sentiment_df = pd.DataFrame(results)\n","        mean_score = sentiment_df['compound'].mean()\n","    else:\n","        mean_score = 0\n","    return mean_score\n","\n","keywords_score_s = {}\n","keywords_score_i = {}\n","\n","for keyword in keywords_sensitive:\n","    mean_score = sentiment_score_s(keyword)\n","    keywords_score_s[keyword] = mean_score\n","\n","for keyword in keywords_insensitive:\n","    mean_score = sentiment_score_i(keyword)\n","    keywords_score_i[keyword] = mean_score\n","\n","\n","list(keywords_frequency_i.values())\n","list(keywords_frequency_i.keys())\n","\n","pd.DataFrame(keywords_frequency_i, index=[n for n in range(len(keywords_frequency_i))])\n","# keywords_frequency_s\n","\n","# keywords_score_s\n","keywords_score_i\n","\n","total_score_i = 0\n","for keyword in keywords_insensitive:\n","    total_score_i += keywords_frequency_i[keyword] * keywords_score_i[keyword]\n","\n","total_score_s = 0\n","for keyword in keywords_sensitive:\n","    total_score_s += keywords_frequency_s[keyword] * keywords_score_s[keyword]\n","\n","\n","sentiment_index = (total_score_i + total_score_s) / (sum(keywords_frequency_i.values()) + sum(keywords_frequency_s.values()))\n","\n","sentiment_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUMuEOnBnLp0","executionInfo":{"status":"ok","timestamp":1642749024543,"user_tz":-540,"elapsed":356210,"user":{"displayName":"­김학순 / 학생 / 건설환경공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLQGJEsB4Jy-3ci7_I7hyLDRG_AwOZRR-xAVx5=s64","userId":"16966179105291263540"}},"outputId":"197f66e2-d6c7-4676-b4fd-66ec30de71af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["0.1842824764645486"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["keywords_score_i"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbBDNdIleV4P","executionInfo":{"status":"ok","timestamp":1642749061085,"user_tz":-540,"elapsed":274,"user":{"displayName":"­김학순 / 학생 / 건설환경공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLQGJEsB4Jy-3ci7_I7hyLDRG_AwOZRR-xAVx5=s64","userId":"16966179105291263540"}},"outputId":"082a96cb-0244-4241-e793-b7715ce346d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Binance': 0.34750585874799317,\n"," 'Bitcoin': 0.19700462214005024,\n"," 'Coinbase': 0.21542004950495056,\n"," 'Crisis': -0.5831675324675336,\n"," 'Cryptocurrency': 0.1734257394084734,\n"," 'Digital': 0.27021996849153207,\n"," 'Doge': 0.39118876669285063,\n"," 'Ethereum': 0.21105377813504833,\n"," 'Exchange': 0.15917568602425025,\n"," 'Invest': 0.054725876129601184,\n"," 'Liquidity': 0.257896875,\n"," 'Market': 0.17467612724757942,\n"," 'Meme': 0.34800296296296307,\n"," 'Money': 0.12798212137780235,\n"," 'NFT': 0.31426872964169417,\n"," 'Price': 0.1278562123039808,\n"," 'Reddit': 0.3438477272727272,\n"," 'Regulation': 0.11928305304010342,\n"," 'SpaceX': 0.1682567415730338,\n"," 'Stock': 0.20057065813528352,\n"," 'Tapering': 0.1599730769230769,\n"," 'Trading': 0.1842981735159817,\n"," 'Wallet': 0.2392320588235294,\n"," 'crackdown': -0.11713301587301601,\n"," 'plunge': -0.14178160000000015}"]},"metadata":{},"execution_count":67}]}]}